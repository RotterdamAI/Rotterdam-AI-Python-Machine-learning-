{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Introduction to Pandas and DataFrames\n",
    "\n",
    "Pandas is a powerful Python library for data manipulation and analysis. It provides high-performance, easy-to-use data structures and data analysis tools. One of the core components of Pandas is the DataFrame, which is a two-dimensional labeled data structure with columns of potentially different data types. This notebook will provide a detailed explanation of Pandas, DataFrames, and common DataFrame operations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "A DataFrame is a two-dimensional tabular data structure in Python, similar to a table in a relational database or a spreadsheet. It is a core data structure in Pandas, a popular library for data manipulation and analysis. A DataFrame consists of rows and columns, where each column can contain data of different types, such as integers, floats, strings, or even other complex data structures.\n",
    "\n",
    "DataFrames are widely used in data analysis tasks as they provide a flexible and powerful way to work with structured data. They allow for easy indexing, slicing, filtering, and transformation of data, making it convenient to perform various operations on datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames\n",
    "\n",
    "You can create a DataFrame from various data sources, such as CSV files, Excel spreadsheets, SQL databases, or even from scratch using Python objects. Here's an example of creating a DataFrame from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['John', 'Emma', 'Michael', 'Sophia'],\n",
    "    'Age': [25, 28, 22, 30],\n",
    "    'City': ['New York', 'Paris', 'London', 'Tokyo']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have a dictionary `data` with three keys ('Name', 'Age', 'City') and corresponding lists as values. We pass this dictionary to the `pd.DataFrame()` function to create a DataFrame `df`. Each key becomes a column name, and the lists become the column values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in files as a dataframe\n",
    "#### CSV (Comma-Separated Values) Files\n",
    "\n",
    "CSV files are a popular tabular data format where values are separated by commas. You can load a CSV file as a DataFrame using the `read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify additional parameters in the read_csv() function, such as the delimiter character, header row, column names, and data types."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel Files\n",
    "\n",
    "Excel files (.xls or .xlsx) are widely used for storing tabular data. Pandas provides the `read_excel()` function to read Excel files and convert them into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('file.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the sheet name or index from the Excel file that you want to load as a DataFrame. Additional parameters include specifying the range of rows or columns, skipping rows or header, and data type conversion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON (JavaScript Object Notation) Files\n",
    "\n",
    "JSON files store structured data in a human-readable format. The `read_json()` function in Pandas allows you to load JSON files as DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('file.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify additional parameters in read_json() to handle complex JSON structures, such as reading specific JSON objects or nested data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other File Formats\n",
    "\n",
    "Pandas supports various other file formats, such as SQL databases, HDF5, Parquet, and more. For each file format, there is a corresponding function to read and load the data into a DataFrame. Some examples include `read_sql()`, `read_hdf()`, and `read_parquet()`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information of your dataframe\n",
    "#### describe() Method\n",
    "The `describe()` method provides a summary of the descriptive statistics for the numerical columns in a DataFrame. It calculates various statistical measures, such as count, mean, standard deviation, minimum, maximum, and quartiles, for each numeric column.\n",
    "\n",
    "Here's how you can use the `describe()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `describe()` method will include the following statistical measures for each numeric column:\n",
    "\n",
    "- count: The number of non-null values in the column.\n",
    "- mean: The average value of the column.\n",
    "- std: The standard deviation, which measures the variability or spread of the values.\n",
    "- min: The minimum value in the column.\n",
    "- 25%: The first quartile, or the value below which 25% of the data falls.\n",
    "- 50%: The second quartile, or the median value.\n",
    "- 75%: The third quartile, or the value below which 75% of the data falls.\n",
    "- max: The maximum value in the column.\n",
    "\n",
    "The `describe()` method provides a quick way to gain insights into the central tendency, dispersion, and distribution of numeric data in a DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### info() Method\n",
    "\n",
    "The `info()` method provides a concise summary of the DataFrame's metadata, including the column names, data types, and information about missing values. It is useful for understanding the structure and composition of the DataFrame.\n",
    "\n",
    "Here's how you can use the `info()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `info()` method will include the following information for each column:\n",
    "\n",
    "- Column Name: The name of the column.\n",
    "- Non-Null Count: The number of non-null values in the column.\n",
    "- Data Type: The data type of the values in the column.\n",
    "- Memory Usage: The memory usage of the column.\n",
    "\n",
    "The `info()` method also provides a summary at the bottom, which includes the total number of columns, the number of non-null values in each column, and the memory usage of the DataFrame.\n",
    "\n",
    "The `info()` method is particularly useful when working with large datasets or when investigating the presence of missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Data in DataFrames\n",
    "#### Column Access\n",
    "\n",
    "You can access a specific column in a DataFrame by using the column name as an index. This will return the column as a Pandas Series. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_column = df['Name']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access multiple columns by providing a list of column names. This will return a new DataFrame with only the specified columns. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[['Name', 'Age']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row Access\n",
    "\n",
    "There are two primary ways to access rows in a DataFrame:\n",
    "\n",
    "- Using `.loc[]`: This indexer allows you to access rows by their labels. You can provide a label or a list of labels to retrieve the corresponding rows. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.loc[0]  # Access the first row\n",
    "subset_rows = df.loc[[0, 2, 4]]  # Access specific rows by labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using `.iloc[]`: This indexer allows you to access rows by their integer positions. You can provide a single integer or a list of integers to retrieve the corresponding rows. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_row = df.iloc[1]  # Access the second row\n",
    "subset_rows = df.iloc[[1, 3, 5]]  # Access specific rows by positions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell Access\n",
    "\n",
    "You can access a specific cell in a DataFrame by combining row and column indices. The <br>`.at[]`indexer allows you to access a specific cell by label-based indexing, while the <br>`.iat[]` indexer allows you to access a specific cell by integer-based indexing. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_value = df.at[0, 'Name']  # Access the cell in the first row and 'Name' column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Operations\n",
    "#### Filtering\n",
    "\n",
    "Filtering allows you to select specific rows based on certain conditions. You can use logical operators, such as `==`, `>`, `<`, `>=`, `<=`, to create Boolean masks and apply them to the DataFrame. This will return a new DataFrame with only the rows that satisfy the condition. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['Age'] > 25]  # Filter rows where 'Age' is greater than 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting\n",
    "\n",
    "Sorting allows you to order the rows or columns of a DataFrame based on specific criteria. You can use the `.sort_values()` method to sort the DataFrame based on one or more columns. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values('Age')  # Sort DataFrame by 'Age' column in ascending order"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding and Removing Columns\n",
    "\n",
    "You can add new columns to a DataFrame or remove existing columns using various methods. To add a new column, you can simply assign a list or a Series to a new column name. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salary'] = [50000, 60000, 55000, 70000]  # Add a new column 'Salary' to the DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove a column, you can use the `.drop()` method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('City', axis=1)  # Remove the 'City' column from the DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating Data\n",
    "\n",
    "Aggregating data involves calculating summary statistics or performing operations on groups of data. You can use various methods, such as `mean()`, `sum()`, `count()`, `min()`, `max()`, to aggregate data in a DataFrame. These methods can be applied to specific columns or to the entire DataFrame. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_age = df['Age'].mean()  # Calculate the average age\n",
    "maximum_salary = df['Salary'].max()  # Find the maximum salary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some of the common DataFrame operations you can perform using Pandas. Remember that Pandas offers a wide range of functions and methods to manipulate, transform, and analyze data in DataFrames, providing powerful capabilities for data analysis tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Missing Values\n",
    "#### fillna() method\n",
    "\n",
    "The `fillna()` method allows you to fill missing values in a DataFrame with a specific value or a predefined strategy. You can use this method to fill missing values with a constant value, the mean or median of the column, or forward/backward fill to propagate the previous/next value.\n",
    "\n",
    "Here's an example of filling missing values with a constant value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)  # Fill missing values with 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ffill and bfill methods\n",
    "\n",
    "The `ffill` method, also known as forward fill, fills missing values with the previous non-null value. Conversely, the `bfill` method, also known as backward fill, fills missing values with the next non-null value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data\n",
    "#### Removing Duplicates\n",
    "The `duplicated()` method allows you to identify and remove duplicate rows from a DataFrame. You can use the `drop_duplicates()` method to remove the duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()  # Remove duplicate rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Irrelevant Columns\n",
    "\n",
    "You can drop unnecessary columns from a DataFrame using the `drop()` method. Specify the column name(s) or a list of column names along with the `axis=1` argument to remove the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['column_name1', 'column_name2'], axis=1)  # Remove specific columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Type Conversion\n",
    "\n",
    "You can use the `astype()` method to convert the data types of one or more columns in a DataFrame. This can be helpful when dealing with columns containing incorrect data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column_name'] = df['column_name'].astype('new_data_type')  # Convert data type of a column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Outliers\n",
    "\n",
    "To handle outliers in a DataFrame, you can use statistical techniques such as z-score or percentiles to detect and filter out values that fall outside a certain range.\n",
    "\n",
    "For example, to remove outliers using z-score, you can calculate the z-score of each value in a column and filter out the values that have a z-score greater than a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "z_scores = stats.zscore(df['column_name'])\n",
    "df = df[(z_scores < threshold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
